{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "ppnp8l-QSryO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('text.txt','r',encoding='utf8')"
      ],
      "metadata": {
        "id": "jV7jfJ0pYHa0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Store file in list \n",
        "lines = []\n",
        "for i in file:\n",
        "  lines.append(i)"
      ],
      "metadata": {
        "id": "KUV7hUB8YT4u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert list to string\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "  data=\" \".join(lines)"
      ],
      "metadata": {
        "id": "NVqKuLR6YmLc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace unnecessary stuff with space\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('\"', '').replace(',', '')"
      ],
      "metadata": {
        "id": "yoCuzHFAZebu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove unnecessary spaces\n",
        "data = data.split() \n",
        "data = ' '.join(data)\n",
        "data[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "5QAiAKbQaAiB",
        "outputId": "f298565e-9015-49d9-abb3-34b04e661b17"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Project Gutenberg eBook of The Adventures of Sherlock Holmes by Arthur Conan Doyle This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States you will have to check the laws of the country where you are locat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG5kZhxbaSY7",
        "outputId": "1c67169f-e840-4576-8b1d-c7663d47b58c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "570593"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "#Saving tokenizer for predict funct\n",
        "pickle.dump(tokenizer, open('token.pkl','wb'))"
      ],
      "metadata": {
        "id": "ntoOGeBkbPKt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converts text/string to numeric representation\n",
        "seq_data = tokenizer.texts_to_sequences([data])[0] \n",
        "seq_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxLHKBlladfo",
        "outputId": "6194e81b-7068-4a47-caf8-d275c470c699"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 144, 129, 875, 4, 1, 1086, 4, 127, 35]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(seq_data) #This length is less than actual because many words are repeated \n",
        "# & each unique word gets 1 numeric representation also it filters any punctuation & white space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WkUTHe1bL1y",
        "outputId": "56c6e26c-6997-4202-bef4-cde8503e82cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110612"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word_index+1 bcz index 0 reserved for padding \n",
        "vocab_size = len(tokenizer.word_index) + 1 \n",
        "print(vocab_size) #these much unique words in our text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-D56LzLbf1F",
        "outputId": "de61bf02-e149-4dd5-8923-18c65c84d176"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = []\n",
        "for i in range(3, len(seq_data)):\n",
        "  words = seq_data[i-3:i+1]\n",
        "  seq.append(words)\n",
        "\n",
        "print(\"The length of Sequences are: \",len(seq))\n",
        "seq = np.array(seq)\n",
        "seq[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U5UBj9Vckwr",
        "outputId": "e3daaf14-5180-4d6a-b8f8-235e5aeaf70f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of Sequences are:  110609\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  144,  129,  875],\n",
              "       [ 144,  129,  875,    4],\n",
              "       [ 129,  875,    4,    1],\n",
              "       [ 875,    4,    1, 1086],\n",
              "       [   4,    1, 1086,    4],\n",
              "       [   1, 1086,    4,  127],\n",
              "       [1086,    4,  127,   35],\n",
              "       [   4,  127,   35,   44],\n",
              "       [ 127,   35,   44,  643],\n",
              "       [  35,   44,  643, 2659]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "for i in seq:\n",
        "  X.append(i[0:3])\n",
        "  Y.append(i[3])\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "metadata": {
        "id": "YiuZ0SLyd8OO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data: \", X[:10])\n",
        "print(\"Response: \", Y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZd8RO9xfDey",
        "outputId": "24d5c034-90be-4428-9e34-7430a03a37e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  [[   1  144  129]\n",
            " [ 144  129  875]\n",
            " [ 129  875    4]\n",
            " [ 875    4    1]\n",
            " [   4    1 1086]\n",
            " [   1 1086    4]\n",
            " [1086    4  127]\n",
            " [   4  127   35]\n",
            " [ 127   35   44]\n",
            " [  35   44  643]]\n",
            "Response:  [ 875    4    1 1086    4  127   35   44  643 2659]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(Y, num_classes= vocab_size)\n",
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B3-VzAYgRgF",
        "outputId": "59a4cd8a-9c6c-4c61-fb49-f00172e3ba5a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Model\n",
        "model= Sequential()\n",
        "model.add(Embedding(vocab_size,10,input_length=3)) #3 input arguments \n",
        "                                                   # - 1st input dimension which is size of vocabulary in my text data\n",
        "                                                   # - 2nd output dimension which is size of vector space in which words will be embedded\n",
        "                                                                                          #size of word vector for each word will be 10.\n",
        "                                                   # - 3rd : use 3 words to predict next word\n",
        "model.add(LSTM(1000, return_sequences=True))                   #1st parameter is no. of units i.e. dimensionality of the output space.\n",
        "                                                               # return_sequences = True indicates I am creating next LSTM layer\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation='relu'))                      # 1000 units- vocab_size - I want my output within this vocabulary\n",
        "                                                               # ReLU - converts negative value to 0 and keeps +ve as it is\n",
        "model.add(Dense(vocab_size, activation = 'softmax'))           # softmax - scales numbers into probabilities "
      ],
      "metadata": {
        "id": "IYiOU_pIgtSe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7wwU9JS_fAo",
        "outputId": "b3e9054b-a1d5-4bc6-846f-cc4b6a09ebc9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 10)             92800     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9280)              9289280   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,431,080\n",
            "Trainable params: 22,431,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "keras.utils.plot_model(model, to_file = 'plot.png', show_layer_names = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "3M-_1rFUA25X",
        "outputId": "9adeb266-a415-46ca-8e1f-b61ffbb105b7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate= 0.001))\n",
        "# Loss function as categorical cross entropy which is used for multi-class classification task \n",
        "# i.e.we have several possible outputs of which my model has to choose one.\n",
        "# Adam optimizer to update the weights iteratively based on training "
      ],
      "metadata": {
        "id": "4xfsWr7cRRaP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint,EarlyStopping \n",
        "mc=ModelCheckpoint(filepath=\"/content/saved_model/best_model.h5\", # best model & weights would go here\n",
        "                   monitor=\"loss\",\n",
        "                   verbose=1,                 #see' the training progress for each epoch only once=1 time\n",
        "                   save_best_only=True) \n",
        "model.fit(X, y, epochs=5,batch_size =1024,callbacks=[mc]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvXKXeuE7teh",
        "outputId": "fdb1994b-3b0a-428f-f437-d6dcf7d6abe0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "109/109 [==============================] - ETA: 0s - loss: 7.0081\n",
            "Epoch 1: loss improved from inf to 7.00811, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 582s 5s/step - loss: 7.0081\n",
            "Epoch 2/5\n",
            "109/109 [==============================] - ETA: 0s - loss: 6.6015\n",
            "Epoch 2: loss improved from 7.00811 to 6.60152, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 562s 5s/step - loss: 6.6015\n",
            "Epoch 3/5\n",
            "109/109 [==============================] - ETA: 0s - loss: 6.5733\n",
            "Epoch 3: loss improved from 6.60152 to 6.57330, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 560s 5s/step - loss: 6.5733\n",
            "Epoch 4/5\n",
            "109/109 [==============================] - ETA: 0s - loss: 6.4164\n",
            "Epoch 4: loss improved from 6.57330 to 6.41638, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 562s 5s/step - loss: 6.4164\n",
            "Epoch 5/5\n",
            "109/109 [==============================] - ETA: 0s - loss: 6.1633\n",
            "Epoch 5: loss improved from 6.41638 to 6.16326, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 560s 5s/step - loss: 6.1633\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f83e6d87090>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint,EarlyStopping \n",
        "mc=ModelCheckpoint(filepath=\"/content/saved_model/best_model.h5\", # best model & weights would go here\n",
        "                   monitor=\"loss\",\n",
        "                   verbose=1,                 #see' the training progress for each epoch only once=1 time\n",
        "                   save_best_only=True) \n",
        "model.fit(X, y, epochs=15,batch_size =1024,callbacks=[mc]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQQeMdGBRvL4",
        "outputId": "9496bd08-faba-4800-e5f6-26127794f746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 4.6796\n",
            "Epoch 1: loss improved from inf to 4.67955, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 580s 5s/step - loss: 4.6796\n",
            "Epoch 2/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 4.4842\n",
            "Epoch 2: loss improved from 4.67955 to 4.48419, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 575s 5s/step - loss: 4.4842\n",
            "Epoch 3/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 4.2905\n",
            "Epoch 3: loss improved from 4.48419 to 4.29045, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 573s 5s/step - loss: 4.2905\n",
            "Epoch 4/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 4.0975\n",
            "Epoch 4: loss improved from 4.29045 to 4.09753, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 583s 5s/step - loss: 4.0975\n",
            "Epoch 5/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 3.9165\n",
            "Epoch 5: loss improved from 4.09753 to 3.91651, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 590s 5s/step - loss: 3.9165\n",
            "Epoch 6/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 3.7436\n",
            "Epoch 6: loss improved from 3.91651 to 3.74360, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 572s 5s/step - loss: 3.7436\n",
            "Epoch 7/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 3.5688\n",
            "Epoch 7: loss improved from 3.74360 to 3.56882, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 572s 5s/step - loss: 3.5688\n",
            "Epoch 8/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 3.4002\n",
            "Epoch 8: loss improved from 3.56882 to 3.40015, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 585s 5s/step - loss: 3.4002\n",
            "Epoch 9/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 3.2618\n",
            "Epoch 9: loss improved from 3.40015 to 3.26176, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 585s 5s/step - loss: 3.2618\n",
            "Epoch 10/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 3.1141\n",
            "Epoch 10: loss improved from 3.26176 to 3.11407, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 584s 5s/step - loss: 3.1141\n",
            "Epoch 11/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.9742\n",
            "Epoch 11: loss improved from 3.11407 to 2.97417, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 578s 5s/step - loss: 2.9742\n",
            "Epoch 12/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.8350\n",
            "Epoch 12: loss improved from 2.97417 to 2.83500, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 586s 5s/step - loss: 2.8350\n",
            "Epoch 13/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.7302\n",
            "Epoch 13: loss improved from 2.83500 to 2.73022, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 588s 5s/step - loss: 2.7302\n",
            "Epoch 14/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.6097\n",
            "Epoch 14: loss improved from 2.73022 to 2.60973, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 602s 6s/step - loss: 2.6097\n",
            "Epoch 15/15\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.5103\n",
            "Epoch 15: loss improved from 2.60973 to 2.51031, saving model to /content/saved_model/best_model.h5\n",
            "109/109 [==============================] - 591s 5s/step - loss: 2.5103\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f877ddf7850>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('/content/saved_model/best_model.h5') "
      ],
      "metadata": {
        "id": "mc4fTNKi8-_G"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "tokenizer = pickle.load(open('token.pkl','rb')) "
      ],
      "metadata": {
        "id": "V1ho8tN8pNxg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def predict(model, tokenizer, text):\n",
        "  seq = tokenizer.texts_to_sequences([text])\n",
        "  seq = np.array(seq)\n",
        "  preds = np.argmax(model.predict(seq))\n",
        "  pred_word = \"\"\n",
        "\n",
        "  for key, value in tokenizer.word_index.items():\n",
        "    if value == preds:\n",
        "      pred_word = key\n",
        "      break\n",
        "\n",
        "  print(pred_word)\n",
        "  return pred_word "
      ],
      "metadata": {
        "id": "LDv_a9lVqOWc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "\n",
        "  if text == '0':\n",
        "    print(\"Excetution completed....\")\n",
        "    break\n",
        "\n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-3:]\n",
        "          print(text)\n",
        "\n",
        "          predict(model, tokenizer, text) \n",
        "\n",
        "      except Exception as e:\n",
        "        print(\"Error occured: \",e)\n",
        "        continue"
      ],
      "metadata": {
        "id": "HWaJY9Qe_Nta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc0ea10-3e21-4834-9aae-1c9e4d36c67b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your line: the use of\n",
            "['the', 'use', 'of']\n",
            "the\n",
            "Enter your line: not located in\n",
            "['not', 'located', 'in']\n",
            "the\n",
            "Enter your line: The Adventures of\n",
            "['The', 'Adventures', 'of']\n",
            "the\n",
            "Enter your line: Author: Arthur Conan\n",
            "['Author:', 'Arthur', 'Conan']\n",
            "Error occured:  in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
            "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 3), found shape=(None, 2)\n",
            "\n",
            "Enter your line: Author Arthur Conan\n",
            "['Author', 'Arthur', 'Conan']\n",
            "little\n",
            "Enter your line: Character set encoding\n",
            "['Character', 'set', 'encoding']\n",
            "the\n",
            "Enter your line: world has seen\n",
            "['world', 'has', 'seen']\n",
            "to\n",
            "Enter your line: throw a doubt\n",
            "['throw', 'a', 'doubt']\n",
            "of\n",
            "Enter your line: or a crack\n",
            "['or', 'a', 'crack']\n",
            "of\n",
            "Enter your line: dubious and questionable\n",
            "['dubious', 'and', 'questionable']\n",
            "the\n",
            "Enter your line: remained in our\n",
            "['remained', 'in', 'our']\n",
            "little\n",
            "Enter your line: I knew little\n",
            "['I', 'knew', 'little']\n",
            "the\n",
            "Enter your line: my way led\n",
            "['my', 'way', 'led']\n",
            "to\n",
            "Enter your line: always be associated\n",
            "['always', 'be', 'associated']\n",
            "to\n",
            "Enter your line: to the chamber\n",
            "['to', 'the', 'chamber']\n",
            "of\n",
            "Enter your line: I fail to\n",
            "['I', 'fail', 'to']\n",
            "the\n",
            "Enter your line: has secreted his\n",
            "['has', 'secreted', 'his']\n",
            "little\n",
            "Enter your line: of my trifling\n",
            "['of', 'my', 'trifling']\n",
            "and\n",
            "Enter your line: shown that you\n",
            "['shown', 'that', 'you']\n",
            "the\n",
            "Enter your line: man who wrote\n",
            "['man', 'who', 'wrote']\n",
            "to\n",
            "Enter your line: 0\n",
            "Excetution completed....\n"
          ]
        }
      ]
    }
  ]
}